[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Glynn Boltman, Comms Blog",
    "section": "",
    "text": "This blog is where I will publish assignments for COMM3180."
  },
  {
    "objectID": "posts/003_DOW1_5b/groundhog_blog.html",
    "href": "posts/003_DOW1_5b/groundhog_blog.html",
    "title": "Dataset of the Week: Philadelphia Weather",
    "section": "",
    "text": "Each February, in Punxsutawney Pennsylvania, Phil the groundhog decides the fate of warm-weather loving athletes across America. If Phil emerges from his hole and sees his shadow, legend says that there will be six more weeks of winter.\nFor Phil’s fans in Philadelphia’s cycling community, the real question isn’t whether the groundhog sees his shadow — it’s how long until the bike can come out of storage.\nI analyzed 20 years of Philadelphia weather data to answer the question every winter-weary cyclist asks: when can I finally ride without freezing?\nThe answer? It depends on the year — and Phil’s timeframe isn’t a reliable range to hope for spring.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nweather_df = pd.read_csv('data/philadelphia_weather_2005_to_2025.csv')\nweather_df = weather_df.assign(date=pd.to_datetime(weather_df['date']))\n\n\n#make a graph that has year on the x axis, and number of days before the weather improves\n#make a new column with a value for whether the weather is &gt; 65 degrees\n#want to change this so that days = number of days after gh day until high temp = 65\n\nghday = pd.to_datetime( #makes a datetime object\n    dict( #for every row the dataset, it'll give the second of feb \n        year=weather_df[\"date\"].dt.year,\n        month=2,\n        day=2))\n\n#all days after Groundhog Day where high &gt; 70\n#example approach\n#winter_filter = (weather_df['date']&gt;=ghday) & (weather_df['date']&lt;=winter_end) #looks at dates between gh and 6 weeks after\nwarm_days = weather_df[(weather_df['date'] &gt;= ghday) & (weather_df['high'] &gt; 70)]\n    #filters by days after groundhog day, AND where tempertature is greater than 70 degrees\n\n#first warm day for each year\nfirst_warm_day = warm_days.groupby('year')['date'].min()\n\n#make a dataset that includes the year and the number of days since ghday it took to get to the warmest day\nghday_by_yr = pd.to_datetime(dict(year=first_warm_day.index, month=2, day=2)) #I had to look up how to change the code you gave us w the index\nghday_by_yr.index = first_warm_day.index  # match the index (also had to look this up)\n\n#finding the number of days it took for the weather to get better\ndays = (first_warm_day - ghday_by_yr).dt.days\n\ndays.mean()\n\nnp.float64(43.23809523809524)\n\n\n\ndays[days == days.min()]\n\nyear\n2018    18\ndtype: int64\n\n\n\ndays[days == days.max()]\n\nyear\n2014    68\ndtype: int64\n\n\nOn average, Philadelphians wait about 43 days after Groundhog Day for the first 75°F high (the perfect cycling weather). But the range is brutal. In 2018, lucky cyclists hit the roads within 18 days. But just four years later, there was a punishing 68 days of waiting, well past when Phil promised spring would arrive.\n\ndays.plot(kind='bar')\n#days.plot(kind='line', style='-o')\nplt.ylabel('Days until first day above 70°F')\nplt.xlabel('Year')\nplt.title('Days from Groundhog Day to First Warm Day')\nplt.show()\n\n\n\n\n\n\n\n\nFurthermore, there doesn’t seem to be a predictable pattern in the number of days until cyclists can reliably set out for the trail. Although 2015 through 2019 may have given false hope for an early spring, there are a clustering of years after 2010 where wait times for good riding weather were well over 40-50 days.\n\n\nEach year, Phil’s predictions fall within a six-week range, meaning that even if past weather patterns give few clues to hopeful sunbathers and sportspeople, maybe a magic groundhog can.\nThe following graph demonstrates in orange, the number of days where it took less than six weeks for the weather to improve. In 12 out of 20 years, it took over 42 days for the weather to improve. In most other cases, it took much longer.\n\n#if days are greater than 6*7 (42), then turn the bar of the graph red\nfill_colors = ['#99CCFF' if d &gt;= 42 else '#FFB266' for d in days]\n#plot\nax = days.plot(kind='bar')\nfill_colors = ['#99CCFF' if d &gt;= 42 else '#FFB266' for d in days] #days until good cycling weather is &gt; six weeks in orange\nfor patch, color in zip(ax.patches, fill_colors):\n    patch.set_facecolor(color)\nplt.ylabel('Days until first day above 70°F')\nplt.xlabel('Year')\nplt.title('Days from Groundhog Day to First Warm Day')\nplt.show()\n\n\n\n\n\n\n\n\nThe key takeaway is that although on average, it will take six weeks for winter to end, from year to year, outdoor athletes shouldn’t plan their rides or runs around a Phil’s time frame. This variaiton suggess that bike commuters should ignore the groundhog and just buy good gloves."
  },
  {
    "objectID": "posts/003_DOW1_5b/groundhog_blog.html#can-phil-schedule-your-tune-up",
    "href": "posts/003_DOW1_5b/groundhog_blog.html#can-phil-schedule-your-tune-up",
    "title": "Dataset of the Week: Philadelphia Weather",
    "section": "",
    "text": "Each year, Phil’s predictions fall within a six-week range, meaning that even if past weather patterns give few clues to hopeful sunbathers and sportspeople, maybe a magic groundhog can.\nThe following graph demonstrates in orange, the number of days where it took less than six weeks for the weather to improve. In 12 out of 20 years, it took over 42 days for the weather to improve. In most other cases, it took much longer.\n\n#if days are greater than 6*7 (42), then turn the bar of the graph red\nfill_colors = ['#99CCFF' if d &gt;= 42 else '#FFB266' for d in days]\n#plot\nax = days.plot(kind='bar')\nfill_colors = ['#99CCFF' if d &gt;= 42 else '#FFB266' for d in days] #days until good cycling weather is &gt; six weeks in orange\nfor patch, color in zip(ax.patches, fill_colors):\n    patch.set_facecolor(color)\nplt.ylabel('Days until first day above 70°F')\nplt.xlabel('Year')\nplt.title('Days from Groundhog Day to First Warm Day')\nplt.show()\n\n\n\n\n\n\n\n\nThe key takeaway is that although on average, it will take six weeks for winter to end, from year to year, outdoor athletes shouldn’t plan their rides or runs around a Phil’s time frame. This variaiton suggess that bike commuters should ignore the groundhog and just buy good gloves."
  },
  {
    "objectID": "posts/005_DOW3/olympic_blog.html",
    "href": "posts/005_DOW3/olympic_blog.html",
    "title": "Going (Abroad) for Gold?",
    "section": "",
    "text": "The olympics would not be complete without nationalist pomp and circumstance. The symbolic summons for states to send their strongest, fastest, and most graceful representatives to compete on the world stage even begins with a show of host-country pride. Even Olympic uniforms are designed to the sequin by representatives of each team’s country, so that olympians are dressed as true patriots.\nBut despite the chest-beating, torch-bearing commitment to countries that Olympic ceremonies imply, not all athletes are competing under their own national flag. In this analysis, I investigate which countries “import” their athletes, exploring which countries’ athletes are most likely to compete with another team, and which countries are most likely to “export” athletes, or send their representatives abroad. Finally, I explore whether athletes competing under another flag are more likely to be successful.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\n\nathletes = pd.read_csv('data/bios_locs.csv')\n    #just keep athlete ID, name, born_country, lat and long\nathletes2 = athletes[['athlete_id', 'born_country', 'lat', 'long']]\nwodat = pd.read_csv('data/winter_olympics_medals.csv')\n    #medals from winter olympics for the whole things\nwodat.shape\n#merge the two datasets: \nwodat = pd.merge(wodat, athletes2, on='athlete_id')\nwodat.shape\nwodat.sample(5)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\nborn_country\nlat\nlong\n\n\n\n\n63926\n2022.0\nWinter\nAlpine Skiing (Skiing)\nGiant Slalom, Men (Olympic)\nYassine Aouich\n148648\nMAR\nNaN\nNaN\nFalse\nNaN\nMAR\nNaN\nNaN\n\n\n44890\n2018.0\nWinter\nBiathlon\n2 × 6 kilometres and 2 × 7.5 kilometres Relay,...\nAnastasia Kuzmina\n118501\nSVK\nSlovakia\nNaN\nFalse\nNaN\nRUS\nNaN\nNaN\n\n\n61125\n2020.0\nWinter\nIce Hockey (Ice Hockey)\nIce Hockey, Boys (YOG)\nLian Bichsel\n139661\nSUI\nSwitzerland\n5.0\nFalse\nNaN\nSUI\nNaN\nNaN\n\n\n12399\n1992.0\nWinter\nFigure Skating (Skating)\nIce Dancing, Mixed (Olympic)\nPaul Duchesnay\n85315\nFRA\nIsabelle Duchesnay\n2.0\nFalse\nSilver\nFRA\nNaN\nNaN\n\n\n16492\n1968.0\nWinter\nSpeed Skating (Skating)\n500 metres, Men (Olympic)\nHerbert Höfl\n87287\nFRG\nNaN\n11.0\nTrue\nNaN\nGER\nNaN\nNaN\n\n\n\n\n\n\n\n\n#summary stats\nwodat.shape\n\n(64509, 14)\n\n\nFirst, I merged datasets that contained information about each winter olympic athlete and competition since 1922 and olympian bios, which contained each olympian’s coumntry of birth.\n\n#making a version of the dataset with only imported/exported athletes\ndatfilt = wodat['noc'] != wodat['born_country']\nimpdat = wodat.loc[datfilt]\nimpdat.shape\n\n#64509-17502 = 47007 \n#dropping about 47,000 rows which seems about right. most olympians compete for their home countries. \n\n(17502, 14)\n\n\n\n#get rid of NA values\ndatfilt2 = impdat['born_country'].notna()\nimpdat = impdat.loc[datfilt2]\nimpdat.sample(5)\n#another 10,000 rows didn't have good location data for where athletes were born\n#wodat['year'].max()\n#wodat['year'].min() #still seem to have good coverage for years though which is good. \n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\nborn_country\nlat\nlong\n\n\n\n\n20418\n1980.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Men (Olympic)\nViktor Lyoskin\n91991\nURS\nNaN\n11.0\nFalse\nNaN\nRUS\nNaN\nNaN\n\n\n2737\n1992.0\nWinter\nSpeed Skating (Skating)\n1,000 metres, Women (Olympic)\nEmese Hunyady\n81329\nAUT\nNaN\n10.0\nFalse\nNaN\nHUN\nNaN\nNaN\n\n\n11982\n1976.0\nWinter\nCross Country Skiing (Skiing)\n50 kilometres, Men (Olympic)\nWalter Demel\n85148\nFRG\nNaN\n25.0\nFalse\nNaN\nGER\nNaN\nNaN\n\n\n24357\n1984.0\nWinter\nNordic Combined (Skiing)\nIndividual, Men (Olympic)\nAleksandr Prosvirnin\n96609\nURS\nNaN\n6.0\nFalse\nNaN\nUKR\nNaN\nNaN\n\n\n9060\n1980.0\nWinter\nCross Country Skiing (Skiing)\n4 × 10 kilometres Relay, Men (Olympic)\nJochen Behle\n83962\nFRG\nWest Germany\n4.0\nFalse\nNaN\nGER\nNaN\nNaN\n\n\n\n\n\n\n\n\nimpdat.shape\n\n(7662, 14)\n\n\n\n#filter to unique athlete values\nimpdat = impdat.drop_duplicates(subset=['as'])\nimpdat.shape\n\n(3286, 14)\n\n\nI then created a subset of this data which only included individual values for athletes whose birth country and the ‘national olympic committee’ that they competed under did not match. This filter repeated rows if an athlete competed for different countries (that were not thier home country) in different years or events, capturing all isntances of movement.\n\nnumimports = impdat.groupby(['noc']).size().to_frame('countrycount').reset_index()\n#counting NOC gives the main countries who import athletes\nnumimports.sort_values('countrycount', ascending = False).head()\n\n\n\n\n\n\n\n\nnoc\ncountrycount\n\n\n\n\n93\nTCH\n440\n\n\n102\nURS\n412\n\n\n35\nFRG\n311\n\n\n82\nROC\n261\n\n\n106\nYUG\n216\n\n\n\n\n\n\n\nNext, I counted how many times a national olympic committe occurred, capturing how often countries were “importers.”\n\n#investigate what country these athletes are really from \nimpdat.loc[impdat['noc'] == 'YUG'].sample(5)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\nborn_country\nlat\nlong\n\n\n\n\n27792\n1924.0\nWinter\nCross Country Skiing (Skiing)\n18 kilometres, Men (Olympic)\nZdenko Švigelj\n98023\nYUG\nNaN\n32.0\nFalse\nNaN\nSLO\nNaN\nNaN\n\n\n29434\n1984.0\nWinter\nIce Hockey (Ice Hockey)\nIce Hockey, Men (Olympic)\nAndrej Vidmar\n98639\nYUG\nYugoslavia\n11.0\nTrue\nNaN\nSLO\nNaN\nNaN\n\n\n7142\n1956.0\nWinter\nCross Country Skiing (Skiing)\n10 kilometres, Women (Olympic)\nBiserka Vodenlič\n82948\nYUG\nNaN\n36.0\nFalse\nNaN\nCRO\nNaN\nNaN\n\n\n9279\n1988.0\nWinter\nAlpine Skiing (Skiing)\nSuper G, Men (Olympic)\nKlemen Bergant\n84028\nYUG\nNaN\n16.0\nFalse\nNaN\nSLO\nNaN\nNaN\n\n\n14547\n1956.0\nWinter\nSki Jumping (Skiing)\nLarge Hill, Individual, Men (Olympic)\nJanez Gorišek\n86147\nYUG\nNaN\n50.0\nFalse\nNaN\nSLO\nNaN\nNaN\n\n\n\n\n\n\n\nThe countries that are the largest importers are Czechoslovakia (TCH), The Union of Soviet Socialist Republics (URS), The German Federation (FRG), The Russian Olympic Committee (ROC), and Yugoslavia (YUG). This makes sense, given that these committes are all results of governments with some kinds of political complexity. Some were were later renamed or dissolved (e.g. the German Federation, or the Russian Olympic Committe). Therefore even if an athlete is Russian, they may be listed as “imported.” Some countries were later partitioned, such as Chechoslovakia, whose athletes are identified as either Czech or Slovak for the most part, and Yugoslavia, whose athletes are from the constituent nations which made up the former Yugoslavia. Finally, the Russian Olympic Committee doesn’t technically represent Russia, since they were banned from the Olympic games in 2023.\n\nworld_gdf = gpd.read_file('data/worldmap.json')\n\ncombined_gdf = pd.merge(world_gdf, \n         numimports,\n         left_on='sov_a3',\n         right_on='noc',\n         how='outer')\n\ncombined_gdf['countrycount']= combined_gdf['countrycount'].fillna(0)\n\n\ncombined_gdf.plot(column='countrycount', \n                  legend=True,\n                  legend_kwds={\n                      'shrink': 0.3,\n                      \n                   },\n                   figsize=(10, 6),\n                vmin=0,\n                vmax=100,\n                   cmap='viridis'\n)\n\nplt.axis('off')\nplt.title('Countries Who Import the Most Olympic Athletes')\nplt.show()\n\n\n\n\n\n\n\n\nThe map demonstrates countries who “import” the most olympic athletes in yellow, with purple or darkered colored countries “importing the least.” Countries in the global south (except for Brazil and Argentina) seem to have less athletes compete under their national banners from abroad, while Europe, Canada, and Russia all host greater numbers of foreign athletes. This might reassure us that athletes from countries who traditionally have better resources and infrastructure for winter sports travel to other countries to avoid competition with conationals. It also might imply that countries on the equator (largely non-importers) are not compensating for a lack of snow by importing winter athletes from other places.\nUnfortunately I’m almost positive that this is wrong because the US isn’t colored grey, and it has at least 200 athletes that aren’t from the US competing for them, additionally, this implies that Canada is the biggest importer, which I’m positive is wrong.\n\nnumexports = impdat.groupby(['born_country']).size().to_frame('countrycount').reset_index()\n\nNext, I explored the countries who are most likely to have an athlete compete under another country’s flag.\n\n#same analysis for sending countries\nnumexports = impdat.groupby(['born_country']).size().to_frame('countrycount').reset_index()\n\ncombined_gdf2 = pd.merge(world_gdf, \n         numexports,\n         left_on='sov_a3',\n         right_on='born_country',\n         how='outer')\n\ncombined_gdf2['countrycount']= combined_gdf2['countrycount'].fillna(0)\n\n\ncombined_gdf2.plot(column='countrycount', \n                  legend=True,\n                  legend_kwds={\n                      'shrink': 0.3,\n                      \n                   },\n                   figsize=(10, 6),\n                vmin=0,\n                vmax=100,\n                   cmap='viridis'\n)\n\nplt.axis('off')\nplt.title('Countries Who Export the Most Olympic Athletes')\nplt.show()\n\n\n\n\n\n\n\n\nThe map demonstrates that there is significant overlap between sending and receiving countries for olympians. Europe, Canada, and Russia, once more, stand out as sending countries for athletes.\n\nnumexports.sort_values('countrycount', ascending = False).head()\n\n\n\n\n\n\n\n\nborn_country\ncountrycount\n\n\n\n\n73\nRUS\n845\n\n\n33\nGER\n551\n\n\n23\nCZE\n433\n\n\n16\nCAN\n232\n\n\n76\nSLO\n179\n\n\n\n\n\n\n\nAs the last analysis demonstrated, places like Russia, Czechoslovakia, and Slovenia, with significant ethnic minorities (or olympic bans) send, or “export,” the most olympic athletes, either to their own or other country’s olympic committees. Canada stands out among these other countries as having fewer athletes that compete at home. To understand why, I looked at where Canadian athletes compete most often.\n\nimpdat.loc[impdat['born_country'] == 'CAN'].groupby('noc').size().to_frame('sends_to').reset_index().sort_values('sends_to', ascending = False).head(10)\n\n\n\n\n\n\n\n\nnoc\nsends_to\n\n\n\n\n16\nITA\n48\n\n\n29\nUSA\n30\n\n\n12\nGBR\n20\n\n\n2\nAUT\n18\n\n\n10\nFRA\n18\n\n\n5\nCHN\n18\n\n\n13\nGER\n15\n\n\n21\nNED\n10\n\n\n17\nJPN\n9\n\n\n25\nSUI\n9\n\n\n\n\n\n\n\nCanada sends most of its athletes to other high income, western countries like as Italy, the United States, Great Britain, Austrlia, and France. In this case, it seems like prospective Canadian olympians may not have had the opportunity to compete for their home teams, perhaps because they face too much domestic competition from other highly skilled winter athletes, and therefore travel to other places where they have the opportunity to compete.\n\n\n\n#original dataset unflitered for import/export athletes: wodat\nwodat['is_import'] = wodat['noc'] != wodat['born_country']\n    #making a column for whether someone competes for the country that they came from\n#wodat.head()\n\nmedal_counts = wodat.groupby(['is_import', 'medal']).size() \nmedal_counts\n#make a column that's t/f for if they're a import/export country or not, then count the medals for each kind of country\n\nis_import  medal \nFalse      Bronze    1876\n           Gold      1761\n           Silver    1856\nTrue       Bronze     658\n           Gold       798\n           Silver     706\ndtype: int64\n\n\nGenerally, it looks like import countries generally do worse in the olympic medal counts…\n\ntotal_athletes = wodat.groupby('is_import').size()\ntotal_athletes\n\nis_import\nFalse    47007\nTrue     17502\ndtype: int64\n\n\nHowever, they also send less athletes to the olympics than non import/export countries. So it’s very possible that they’re actually outperforming these countries in a way that raw medal counts don’t factor in. To better understand this problem, we can solve for the proportions of medals given the number of total sending athletes.\n\nmedal_proportions = medal_counts / total_athletes\nmedal_proportions.round(4)*100\n\nis_import  medal \nFalse      Bronze    3.99\n           Gold      3.75\n           Silver    3.95\nTrue       Bronze    3.76\n           Gold      4.56\n           Silver    4.03\ndtype: float64\n\n\nThe table tells us that, in fact, import/export athletes outcompete athletes who represent their own countries in relative terms. For example, only 3.75% of native-country athletes won a Gold metal in the time period analyzed, while 4.56 import/export athletes won Gold. In fact, the only medal category in which native-country athletes do better is in the Bronze category.\nThis relative high performance could be due to a many factors. The results of the earlier data analysis show that Russia, traditionally one of the most competitive countries in the winter olympics, is also the highest importer and exporter of athletes. Therefore the final medal counts could simply overrepresent one exceptionally high-acheiving country.\nHowever the presence of countries like Canada suggests that athletes who are most likely to move countries in order to compete for the olympics may also compete at a higher level. At the very least, they likely have greater resources than their less-mobile peers."
  },
  {
    "objectID": "posts/005_DOW3/olympic_blog.html#do-importexported-athletes-win-more-often-than-local-athletes",
    "href": "posts/005_DOW3/olympic_blog.html#do-importexported-athletes-win-more-often-than-local-athletes",
    "title": "Going (Abroad) for Gold?",
    "section": "",
    "text": "#original dataset unflitered for import/export athletes: wodat\nwodat['is_import'] = wodat['noc'] != wodat['born_country']\n    #making a column for whether someone competes for the country that they came from\n#wodat.head()\n\nmedal_counts = wodat.groupby(['is_import', 'medal']).size() \nmedal_counts\n#make a column that's t/f for if they're a import/export country or not, then count the medals for each kind of country\n\nis_import  medal \nFalse      Bronze    1876\n           Gold      1761\n           Silver    1856\nTrue       Bronze     658\n           Gold       798\n           Silver     706\ndtype: int64\n\n\nGenerally, it looks like import countries generally do worse in the olympic medal counts…\n\ntotal_athletes = wodat.groupby('is_import').size()\ntotal_athletes\n\nis_import\nFalse    47007\nTrue     17502\ndtype: int64\n\n\nHowever, they also send less athletes to the olympics than non import/export countries. So it’s very possible that they’re actually outperforming these countries in a way that raw medal counts don’t factor in. To better understand this problem, we can solve for the proportions of medals given the number of total sending athletes.\n\nmedal_proportions = medal_counts / total_athletes\nmedal_proportions.round(4)*100\n\nis_import  medal \nFalse      Bronze    3.99\n           Gold      3.75\n           Silver    3.95\nTrue       Bronze    3.76\n           Gold      4.56\n           Silver    4.03\ndtype: float64\n\n\nThe table tells us that, in fact, import/export athletes outcompete athletes who represent their own countries in relative terms. For example, only 3.75% of native-country athletes won a Gold metal in the time period analyzed, while 4.56 import/export athletes won Gold. In fact, the only medal category in which native-country athletes do better is in the Bronze category.\nThis relative high performance could be due to a many factors. The results of the earlier data analysis show that Russia, traditionally one of the most competitive countries in the winter olympics, is also the highest importer and exporter of athletes. Therefore the final medal counts could simply overrepresent one exceptionally high-acheiving country.\nHowever the presence of countries like Canada suggests that athletes who are most likely to move countries in order to compete for the olympics may also compete at a higher level. At the very least, they likely have greater resources than their less-mobile peers."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/000_test_post/index.html#stories-from-data",
    "href": "posts/000_test_post/index.html#stories-from-data",
    "title": "A test post",
    "section": "Stories from data",
    "text": "Stories from data\n\nLet’s set up some data\n\n\nx = ['A', 'B', 'C']\ny = [1, 5, 3]\n\n\nNow let’s visualize it\n\nplt.bar(x, y)\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Data Stories",
    "section": "",
    "text": "Going (Abroad) for Gold?\n\n\n\ncoursework\n\n\n\nDataset of the Week 3: Olympic Data\n\n\n\n\n\nFeb 24, 2026\n\n\nGlynn Boltman\n\n\n\n\n\n\n\n\n\n\n\n\nDataset of the Week: Philadelphia Weather\n\n\n\ncoursework\n\n\n\nBlog Post 2, Groundhog Day Analysis\n\n\n\n\n\nFeb 6, 2026\n\n\nGlynn Boltman\n\n\n\n\n\n\n\n\n\n\n\n\nIntroverts Online\n\n\n\ncoursework\n\n\n\nDataset of the Week 2: Big 5 Personality Test\n\n\n\n\n\nFeb 6, 2026\n\n\nGlynn Boltman\n\n\n\n\n\n\n\n\n\n\n\n\nDataset of the Week, Glynn (DOWG)\n\n\n\ncoursework\n\n\n\nAssignment 2 for GitHub\n\n\n\n\n\nJan 28, 2026\n\n\nGlynn Boltman\n\n\n\n\n\n\n\n\n\n\n\n\nTesting, 123\n\n\n\nvisualization\n\ndata stories\n\ncomms\n\nother category\n\n\n\nClever subtitle here\n\n\n\n\n\nJan 23, 2026\n\n\nGlynn Boltman\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nvisualization\n\ndata stories\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nJan 12, 2026\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/001_first_post/renamed_post1.html",
    "href": "posts/001_first_post/renamed_post1.html",
    "title": "Testing, 123",
    "section": "",
    "text": "# ^ this is what you have to put at the beginning of every post (but be careful, because people can see commented cells)\n# be careful that the code cell is raw"
  },
  {
    "objectID": "posts/001_first_post/renamed_post1.html#this-is-what-im-writing-for-content.",
    "href": "posts/001_first_post/renamed_post1.html#this-is-what-im-writing-for-content.",
    "title": "Testing, 123",
    "section": "This is what I’m writing for content.",
    "text": "This is what I’m writing for content.\nIt’s just practice, more to come!"
  },
  {
    "objectID": "posts/002_second_post/in_class_practice.html",
    "href": "posts/002_second_post/in_class_practice.html",
    "title": "Dataset of the Week, Glynn (DOWG)",
    "section": "",
    "text": "Important information:"
  },
  {
    "objectID": "posts/004_DOW2/big5_blog.html",
    "href": "posts/004_DOW2/big5_blog.html",
    "title": "Introverts Online",
    "section": "",
    "text": "Personality tests can tell us whether people are more likely to do any number of things. People who identify as “thinkers” rather than feelers might be more likely to make pro-con lists for difficult decisions. “Perceivers” might be more likely than “judgers” to go on a spontaneous trip, or try new things. But is it fair to say that certain personality types reliably act in a certain way?\nIn this analysis, I investigate whether extroverts more active on social media.\nIn the Meyers’ Brigs (personality) Type Indicator (MBTI), Introversion (I) and Extroversion (E) define how people direct their energy and interact with the world. I expect that people who are more extroverted will be more likely to interact with others, even online! However the opposite may be true, that introverts prefer online interactions to in person interactions, and are therefore more likely to replace in-person conversations with social media ones.\nUnderstanding the likelihood that different personality types post on social media might tell us which of these hypotheses drive behavior for different kinds of people.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Markdown, display\n    #had to look this up\n\n\nsm = pd.read_csv('data/mbti.csv')\n\nFirst, I discovered how many people posting on social media are extroverts. After all, there’s a possibility that just by nature of being more social, they’re more likely to be incldued in the dataset. To identify this, I counted the number of people who identify as extroverted (“E” in the dataset) compared to the number of people who identify as introverted (“I” in the dataset).\n\n#split the type column into each of the identifiers\nsm['M'] = sm['type'].str[0]\nsm['B'] = sm['type'].str[1]\nsm['T'] = sm['type'].str[2]\nsm['I'] = sm['type'].str[3]\n\n#basic summary statistics for the numbers of each personality trait\nsm['M'].value_counts()\n\nM\nI    6676\nE    1999\nName: count, dtype: int64\n\n\n\nintrovert = sm['M'].value_counts().iloc[0]\nextrovert = sm['M'].value_counts().iloc[1]\n\n\nmkdwm_str = f'''\nSurprisingly, the number of introverts in the dataset **({introvert})** is far larger than the number of extroverts **({extrovert})**. \n\nTo see whether this kind of variation in personality traits was spread consistently across the dataset, or whether my sample might be skewed toward a certain personality, I plotted the frequency of different MBTI identifiers.\n'''\ndisplay(Markdown(mkdwm_str))\n\nSurprisingly, the number of introverts in the dataset (6676) is far larger than the number of extroverts (1999).\nTo see whether this kind of variation in personality traits was spread consistently across the dataset, or whether my sample might be skewed toward a certain personality, I plotted the frequency of different MBTI identifiers.\n\n\n\n#making a dataframe so I can plot the whole set of personality traits in the dataset\n    #I didn't realize until later that MBTI just stands for meyers briggs personality types, \n    #but these were still useful identifiers for the labels, which I made in this dictionary\ncounts = pd.DataFrame({\n    'Introversion/Extraversion ': sm['M'].value_counts(),\n    'Sensing/Intuition': sm['B'].value_counts(),\n    'Thinking/Feeling': sm['T'].value_counts(),\n    'Judging/Perceiving': sm['I'].value_counts()\n})\n\n#had to look up how to do this, because the pandas plot from the 03 slides for this week wasn't super customizable\n    #how I understand this is that fig changes the canvas size and ax manages the plot itself\n    #it's the same as saying: \n        # result = plt.subplots()\n        # fig = result[0]  # the figure\n        # ax = result[1]   # the axes\n    #which assigns a figure and axis so I can manage these separately\nfig, ax = plt.subplots(figsize=(10, 6))\ncounts.transpose().plot(kind='barh', ax=ax, width=.9) \nax.set_xlabel('Count', fontsize=12)\nax.set_ylabel('Dimension', fontsize=12)\nax.set_title('MBTI Personality Trait Distribution', fontsize=14)\nax.legend(title='Type')\nax.grid(axis='x', linestyle='--', alpha=0.7)\nplt.tight_layout() #had to look this up, but I still don't understand why my spacing is so strange\nplt.show()\n\n\n\n\n\n\n\n\nIt appears that much like the introversion/extroversion element of the Meyers Briggs personality type, there is a wide gap between respondents who identify as Intuitive vs. Sensing personality types. There are more similar distributions between the Judging/Perceivng and the Thinking/Feeling categories.\nTherefore, if we assume that our sample is representative of the entire population, the high number of introverts in out data might support the second hypotheses. Because introverts are less predisposed to social interactions, they are more likely to engage online. This may be a replacement of otherwise in-person conversations.\n\n\nAlthough more introverts in the sample supports the second hypothesis, this may also be a quirk of data collection. Perhaps the specific online forum of MBTI personalities is more likely to include introverts for some other systematic reason, unrelated to personality type.\nTo further test my hypotheses, I checked the length of posts for different personality types.\n\nsm['post_length'] = sm['posts'].str.len() #take the length\nsm[1:3]\n\n\n\n\n\n\n\n\nfilename\ntype\nposts\nM\nB\nT\nI\npost_length\n\n\n\n\n1\n1\nENTP\n'I'm finding the lack of me in these posts ver...\nE\nN\nT\nP\n7053\n\n\n2\n2\nINTP\n'Good one  _____   https://www.youtube.com/wat...\nI\nN\nT\nP\n5265\n\n\n3\n3\nINTJ\n'Dear INTP,   I enjoyed our conversation the o...\nI\nN\nT\nJ\n6271\n\n\n4\n4\nENTJ\n'You're fired.|||That's another silly misconce...\nE\nN\nT\nJ\n6111\n\n\n\n\n\n\n\n\n#take the mean of the I and E groups in the M column to see the average post length\nlen_by_ei = sm.groupby('M')['post_length'].mean()\nlen_by_ei\n\nM\nE    7198.235118\nI    7245.995057\nName: post_length, dtype: float64\n\n\n\nlen_by_ei['E'] &gt; len_by_ei['I'] #unclear why I couldn't use 1 and 0 here. Different data types? \n\nnp.False_\n\n\n\n(len_by_ei['E'] - len_by_ei['I']).round()\n\nnp.float64(-48.0)\n\n\nConsistent with my earlier findings, it seems like introverts are more active on social media than extroverts. On average, extroverts will use 48 less characters in a post than introverts."
  },
  {
    "objectID": "posts/004_DOW2/big5_blog.html#is-there-a-difference-in-how-introverts-and-extroverts-engage-online",
    "href": "posts/004_DOW2/big5_blog.html#is-there-a-difference-in-how-introverts-and-extroverts-engage-online",
    "title": "Introverts Online",
    "section": "",
    "text": "Although more introverts in the sample supports the second hypothesis, this may also be a quirk of data collection. Perhaps the specific online forum of MBTI personalities is more likely to include introverts for some other systematic reason, unrelated to personality type.\nTo further test my hypotheses, I checked the length of posts for different personality types.\n\nsm['post_length'] = sm['posts'].str.len() #take the length\nsm[1:3]\n\n\n\n\n\n\n\n\nfilename\ntype\nposts\nM\nB\nT\nI\npost_length\n\n\n\n\n1\n1\nENTP\n'I'm finding the lack of me in these posts ver...\nE\nN\nT\nP\n7053\n\n\n2\n2\nINTP\n'Good one  _____   https://www.youtube.com/wat...\nI\nN\nT\nP\n5265\n\n\n3\n3\nINTJ\n'Dear INTP,   I enjoyed our conversation the o...\nI\nN\nT\nJ\n6271\n\n\n4\n4\nENTJ\n'You're fired.|||That's another silly misconce...\nE\nN\nT\nJ\n6111\n\n\n\n\n\n\n\n\n#take the mean of the I and E groups in the M column to see the average post length\nlen_by_ei = sm.groupby('M')['post_length'].mean()\nlen_by_ei\n\nM\nE    7198.235118\nI    7245.995057\nName: post_length, dtype: float64\n\n\n\nlen_by_ei['E'] &gt; len_by_ei['I'] #unclear why I couldn't use 1 and 0 here. Different data types? \n\nnp.False_\n\n\n\n(len_by_ei['E'] - len_by_ei['I']).round()\n\nnp.float64(-48.0)\n\n\nConsistent with my earlier findings, it seems like introverts are more active on social media than extroverts. On average, extroverts will use 48 less characters in a post than introverts."
  }
]